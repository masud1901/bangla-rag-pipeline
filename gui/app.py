import streamlit as st
import requests
import json
import time
from datetime import datetime
import pandas as pd

# --- Page Configuration ---
st.set_page_config(
    page_title="Multilingual RAG System",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- API Configuration ---
FASTAPI_BASE_URL = "http://rag-api:8000"
QUERY_URL = f"{FASTAPI_BASE_URL}/query"
HEALTH_URL = f"{FASTAPI_BASE_URL}/health"
DEBUG_URL = f"{FASTAPI_BASE_URL}/debug/retrieve"

# --- Helper Functions ---
def get_system_health():
    try:
        response = requests.get(HEALTH_URL, timeout=5)
        return response.json() if response.status_code == 200 else None
    except:
        return None

def get_debug_info(query: str, language: str = None):
    """Get debug information about retrieval without generating answer."""
    if language is None:
        language = detect_language(query)
    payload = {
        "query": query,
        "language": language,
        "top_k": 12
    }
    try:
        response = requests.post(DEBUG_URL, json=payload, timeout=60)
        return response.json() if response.status_code == 200 else None
    except:
        return None

def detect_language(text):
    bengali_chars = set('à¦…à¦†à¦‡à¦ˆà¦‰à¦Šà¦‹à¦à¦à¦“à¦”à¦•à¦–à¦—à¦˜à¦™à¦šà¦›à¦œà¦à¦à¦Ÿà¦ à¦¡à¦¢à¦£à¦¤à¦¥à¦¦à¦§à¦¨à¦ªà¦«à¦¬à¦­à¦®à¦¯à¦°à¦²à¦¶à¦·à¦¸à¦¹à¦¡à¦¼à¦¢à¦¼à¦¯à¦¼à§à¦‚à¦ƒ')
    bengali_count = sum(1 for char in text if char in bengali_chars)
    return "bn" if bengali_count > len(text) * 0.1 else "en"

def get_answer(query: str, language: str = None, include_sources: bool = True):
    if language is None:
        language = detect_language(query)
    payload = {
        "query": query,
        "language": language,
        "include_sources": include_sources,
        "top_k": 5
    }
    try:
        start_time = time.time()
        response = requests.post(QUERY_URL, json=payload, timeout=120)
        end_time = time.time()
        if response.status_code == 200:
            result = response.json()
            result["client_processing_time"] = (end_time - start_time) * 1000
            return result
        else:
            st.error(f"API Error: {response.status_code} - {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        st.error(f"Connection Error: {e}")
        return None

# --- Session State Initialization ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "query_history" not in st.session_state:
    st.session_state.query_history = []
if "current_language" not in st.session_state:
    st.session_state.current_language = "auto"

# --- Sidebar ---
with st.sidebar:
    st.title("ğŸ“š Multilingual RAG")
    st.markdown("Ask questions in **à¦¬à¦¾à¦‚à¦²à¦¾** or **English** about the textbook.")
    
    # System Status
    st.subheader("ğŸ”§ System Status")
    health_data = get_system_health()
    if health_data:
        status = health_data.get("status", "unknown")
        if status == "healthy":
            st.success("âœ… System Online")
        else:
            st.error("âŒ System Offline")
        
        # Show vector store stats
        config = health_data.get("config", {})
        index_stats = config.get("index_stats", {})
        
        if index_stats:
            summary = index_stats.get("summary", {})
            total_vectors = summary.get("total_vectors", 0)
            collections = summary.get("collections", [])
            
            st.info(f"ğŸ“Š Total Vectors: {total_vectors}")
            if collections:
                st.info(f"ğŸ“š Collections: {', '.join(collections)}")
            
            # Show individual collection stats
            for collection_name, stats in index_stats.items():
                if collection_name != "summary":
                    vector_count = stats.get("total_vectors", 0)
                    if vector_count > 0:
                        st.success(f"âœ… {collection_name.title()}: {vector_count} vectors")
                    else:
                        st.warning(f"âš ï¸ {collection_name.title()}: {vector_count} vectors")
    else:
        st.error("âŒ Cannot connect to API")
    
    # Language Selection
    st.subheader("ğŸŒ Language")
    language_option = st.selectbox(
        "Response Language",
        ["auto", "en", "bn"],
        format_func=lambda x: {
            "auto": "ğŸ”„ Auto-detect",
            "en": "ğŸ‡ºğŸ‡¸ English", 
            "bn": "ğŸ‡§ğŸ‡© à¦¬à¦¾à¦‚à¦²à¦¾"
        }[x]
    )
    st.session_state.current_language = language_option
    
    # Sample Questions
    st.subheader("ğŸ’¡ Sample Questions")
    sample_questions = {
        "ğŸ‡§ğŸ‡© Bengali": [
            "à¦®à¦¾à¦¨à¦¬à¦¿à¦• à¦šà§‡à¦¤à¦¨à¦¾ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦•à§€ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?",
            "à¦®à¦¾à¦¨à¦¬-à¦•à¦²à§à¦¯à¦¾à¦£à§‡à¦° à¦…à¦°à§à¦¥ à¦•à§€?",
            "à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶à§‡à¦° à¦®à¦¹à§ à¦¬à§à¦¯à¦•à§à¦¤à¦¿à¦¦à§‡à¦° à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦•à§€ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?",
            "à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡à¦° à¦—à§à¦°à§à¦¤à§à¦¬ à¦•à§€?",
        ],
        "ğŸ‡ºğŸ‡¸ English": [
            "What is human consciousness?",
            "What is human welfare?",
            "What is said about great personalities of Bangladesh?",
            "What is the importance of relationships?",
        ]
    }
    
    for lang, questions in sample_questions.items():
        st.markdown(f"**{lang}:**")
        for q in questions:
            if st.button(q, key=f"sample_{q}", use_container_width=True):
                st.session_state.sample_query = q
                st.rerun()
    
    # Stats
    if st.session_state.query_history:
        st.subheader("ğŸ“ˆ Statistics")
        df = pd.DataFrame(st.session_state.query_history)
        avg_time = df['processing_time'].mean()
        st.metric("Avg Response", f"{avg_time:.0f}ms")
        st.metric("Total Queries", len(df))
    
    # Actions
    st.subheader("âš™ï¸ Actions")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ—‘ï¸ Clear Chat", use_container_width=True):
            st.session_state.messages = []
            st.rerun()
    with col2:
        if st.button("ğŸ“Š Export", use_container_width=True):
            if st.session_state.messages:
                chat_data = json.dumps(st.session_state.messages, default=str, indent=2)
                st.download_button(
                    label="ğŸ’¾ Download",
                    data=chat_data,
                    file_name=f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )
    
    # Debug Section
    st.subheader("ğŸ” Debug Tools")
    if st.button("ğŸ”¬ Test Debug Endpoint", use_container_width=True):
        test_query = "à¦®à¦¾à¦¨à¦¬à¦¿à¦• à¦šà§‡à¦¤à¦¨à¦¾"
        debug_info = get_debug_info(test_query)
        if debug_info:
            st.json(debug_info)
        else:
            st.error("Debug endpoint not available")

# --- Main Chat Interface ---
st.title("ğŸ’¬ Multilingual RAG Chat")
st.caption("Ask questions about HSC Bangla Literature in à¦¬à¦¾à¦‚à¦²à¦¾ or English")

# Handle sample question selection
if 'sample_query' in st.session_state:
    prompt = st.session_state.sample_query
    del st.session_state.sample_query
else:
    prompt = None

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # Show sources if available
        if message["role"] == "assistant" and "sources" in message and message["sources"]:
            with st.expander(f"ğŸ“š Sources ({len(message['sources'])} found)"):
                for i, chunk in enumerate(message["sources"], 1):
                    st.markdown(f"**Page {chunk.get('page_number', 'N/A')}** (Score: {chunk.get('relevance_score', 0):.2f})")
                    st.markdown(f"> {chunk.get('text', 'No text available')[:200]}...")
        
        # Show metadata if available
        if message["role"] == "assistant" and "metadata" in message:
            with st.expander("ğŸ” Details"):
                meta = message["metadata"]
                st.json(meta)

# Chat input
if not prompt:
    prompt = st.chat_input("Ask your question in English or à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦ªà§à¦°à¦¶à§à¦¨ à¦•à¦°à§à¦¨...")

if prompt:
    # Add user message
    detected_lang = detect_language(prompt)
    use_lang = detected_lang if st.session_state.current_language == "auto" else st.session_state.current_language
    
    st.session_state.messages.append({
        "role": "user", 
        "content": prompt,
        "language": use_lang,
        "timestamp": datetime.now()
    })
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Get and display assistant response
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” Thinking..."):
            api_response = get_answer(prompt, use_lang, include_sources=True)
        
        if api_response:
            answer = api_response.get("answer", "No answer found.")
            sources = api_response.get("source_chunks", [])
            
            st.markdown(answer)
            
            # Add assistant message to history
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer,
                "sources": sources,
                "metadata": {
                    "processing_time_ms": api_response.get("processing_time_ms", 0),
                    "retrieved_chunks_count": len(sources),
                    "embedding_model": api_response.get("model_info", {}).get("embedding_model", "N/A"),
                    "llm_model": api_response.get("model_info", {}).get("llm", "N/A")
                },
                "timestamp": datetime.now()
            })
            
            # Update query history
            st.session_state.query_history.append({
                "query": prompt,
                "language": use_lang,
                "processing_time": api_response.get("processing_time_ms", 0),
                "chunks_found": len(sources),
                "timestamp": datetime.now()
            })
            
            # Show sources if available
            if sources:
                with st.expander(f"ğŸ“š Sources ({len(sources)} found)"):
                    for i, chunk in enumerate(sources, 1):
                        st.markdown(f"**Page {chunk.get('page_number', 'N/A')}** (Score: {chunk.get('relevance_score', 0):.2f})")
                        st.markdown(f"> {chunk.get('text', 'No text available')[:200]}...")
            
            # Show metadata
            with st.expander("ğŸ” Response Details"):
                st.json({
                    "Processing Time (ms)": api_response.get("processing_time_ms", 0),
                    "Chunks Retrieved": len(sources),
                    "Model": api_response.get("model_info", {}).get("embedding_model", "N/A"),
                    "LLM Model": api_response.get("model_info", {}).get("llm", "N/A"),
                    "Rerank Model": api_response.get("model_info", {}).get("rerank_model", "N/A")
                })
                
                # Show retrieval stats if available
                retrieval_stats = api_response.get("retrieval_stats", {})
                if retrieval_stats:
                    st.subheader("ğŸ“Š Retrieval Statistics")
                    st.json(retrieval_stats)
        else:
            error_msg = "âŒ Sorry, I encountered an error. Please check the system status and try again."
            st.markdown(error_msg)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": error_msg,
                "timestamp": datetime.now()
            })

# Footer
st.markdown("---")
st.markdown("**Made with â¤ï¸ using Streamlit & FastAPI**") 